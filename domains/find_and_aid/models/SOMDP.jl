using Combinatorics
using Statistics
using Random

import Base.==

include("MDP.jl")
include(joinpath(@__DIR__, "..", "..", "..", "solvers", "VIMDPSolver.jl"))
include(joinpath(@__DIR__, "..", "..", "..", "solvers", "LAOStarSolver.jl"))

function index(element, collection)
    for i=1:length(collection)
        if collection[i] == element
            return i
        end
    end
    return -1
end

struct MemoryState
    state::DomainState
    action_list::Vector{DomainAction}
end

function ==(sâ‚::MemoryState, sâ‚‚::MemoryState)
    return (sâ‚.state == sâ‚‚.state && sâ‚.action_list == sâ‚‚.action_list)
end

struct MemoryAction
    value::Union{String,Char}
end

struct SOMDP
    M::MDP
    S::Vector{MemoryState}
    A::Vector{MemoryAction}
    T::Function
    R::Function
   sâ‚€::MemoryState
    Ï„::Dict{Int, Dict{Int, Dict{Int, Float64}}}
    Î´::Integer
    H::Function
end

function generate_states(M::MDP, Î´::Integer)
    A = M.A

    S = Vector{MemoryState}()
    sâ‚€ = -1
    for depth in 0:Î´
        for (i, state) in enumerate(M.S)
            if depth == 0
                s = MemoryState(state, Vector{DomainAction}())
                push!(S, s)
                if state == M.sâ‚€
                    sâ‚€ = length(S)
                end
            else
                for action_list âˆˆ collect(Base.product(ntuple(i->A, depth)...))
                    s = MemoryState(state, [a for a âˆˆ action_list])
                    push!(S, s)
                end
            end
        end
    end
    push!(S, MemoryState(DomainState(-1, -1, 'â†‘', -1, Integer[-1,-1,-1]),
                         DomainAction[DomainAction("aid")]))
    return S, S[sâ‚€]
end

function terminal(state::MemoryState)
    return terminal(state.state)
end

function generate_actions(M::MDP)
    A = [MemoryAction(a.value) for a in M.A]
    push!(A, MemoryAction("QUERY"))
    return A
end

function eta(action::MemoryAction,
             stateâ€²::MemoryState)
    return 0.3 * stateâ€².state.ğ“
end

function recurse_transition(â„³::SOMDP,
                         state::MemoryState,
                        action::MemoryAction,
                        stateâ€²::MemoryState)::Float64
    s, a, sâ€² = index(state, â„³.S), index(action, â„³.A), index(stateâ€², â„³.S)

    if isempty(state.action_list)
        return â„³.M.T[s][a][sâ€²]
    end

    if s âˆˆ keys(â„³.Ï„)
        if a âˆˆ keys(â„³.Ï„[s])
            if sâ€² âˆˆ keys(â„³.Ï„[s][a])
                return â„³.Ï„[s][a][sâ€²]
            end
        else
            â„³.Ï„[s][a] = Dict{Int, Float64}()
        end
    else
        â„³.Ï„[s] = Dict(a => Dict{Int, Float64}())
    end

    actionâ‚š = MemoryAction(last(state.action_list).value)
    stateâ‚š = MemoryState(state.state,
                         state.action_list[1:length(state.action_list)-1])
    p = 0.

    for bs=1:length(â„³.M.S)
        q = â„³.M.T[bs][a][sâ€²]
        if q â‰  0.
            p += q * recurse_transition(â„³, stateâ‚š, actionâ‚š, â„³.S[bs])
        end
    end

    â„³.Ï„[s][a][sâ€²] = p
    return p
end

function generate_transitions(â„³::SOMDP,
                           state::MemoryState,
                          action::MemoryAction)
    M, S, A = â„³.M, â„³.S, â„³.A
    T = zeros(length(S))
    if state.state.x == -1
        T[length(â„³.S)] = 1.0
        return T
    end
    if isempty(state.action_list)
        s, a = index(state, S), index(action, A)
        if action.value == "QUERY"
            T[s] = 1.
            return T
        elseif maximum(M.T[s][a]) == 1.
            T[argmax(M.T[s][a])] = 1.
            return T
        else
            msâ€² = length(M.S) + length(M.A) * (s-1) + a
            T[msâ€²] = eta(action, â„³.S[msâ€²])
            for (sâ€², stateâ€²) in enumerate(M.S)
                T[sâ€²] = M.T[s][a][sâ€²] * (1 - T[msâ€²])
            end
        end
    elseif action.value == "QUERY"
        actionâ‚š = MemoryAction(last(state.action_list).value)
        stateâ‚š = MemoryState(state.state,
                             state.action_list[1:length(state.action_list)-1])
        for sâ€² = 1:length(M.S)
            T[sâ€²] = recurse_transition(â„³, stateâ‚š, actionâ‚š, S[sâ€²])
        end
    elseif length(state.action_list) == â„³.Î´
        T[length(â„³.S)] = 1.
    else
        action_listâ€² = copy(state.action_list)
        push!(action_listâ€², DomainAction(action.value))
        mstateâ€² = MemoryState(state.state, action_listâ€²)
        ## TODO: Below, we assume a fixed value of gaining observability from a
        ##       memory state. THis part should be changed to be based on eta
        ##       of belief state of the memory state.
        T[index(mstateâ€², S)] = .75
        for sâ€² = 1:length(M.S)
            T[sâ€²] = 0.25recurse_transition(â„³, state, action, S[sâ€²])
        end
    end
    return T
end

function generate_reward(â„³::SOMDP,
                      state::MemoryState,
                     action::MemoryAction)
    M, S, A = â„³.M, â„³.S, â„³.A
    if state.state.x == -1
        return -10
    end
    if action.value == "QUERY"
        return -3.  ## TODO: Adjust this cost somehow??
    elseif length(state.action_list) == 0
        return M.R[index(state, S)][index(action, A)]
    else
        a = index(action, A)
        actionâ‚š = MemoryAction(last(state.action_list).value)
        stateâ‚š = MemoryState(state.state,
                             state.action_list[1:length(state.action_list)-1])
        return (sum(M.R[bs][a] * recurse_transition(â„³, stateâ‚š, actionâ‚š, S[bs])
                                                      for bs = 1:length(M.S)))
    end
end

function generate_heuristic(â„³::SOMDP,
                             V::Vector{Float64},
                         state::MemoryState,
                        action::MemoryAction)
    M, S, A = â„³.M, â„³.S, â„³.A
    if state.state.x == -1
        return 0.
    end
    if length(state.action_list) == 0
        return V[index(state, S)]
    else
        actionâ‚š = MemoryAction(last(state.action_list).value)
        stateâ‚š = MemoryState(state.state,
                            state.action_list[1:length(state.action_list)-1])
        h = 0.0
        for bs = 1:length(M.S)
            v = V[bs]
            if v â‰  0.0
                h += v * recurse_transition(â„³, stateâ‚š, actionâ‚š, S[bs])
            end
        end
        return h
        # return (sum(V[bs] * recurse_transition(â„³, stateâ‚š, actionâ‚š, S[bs])
        #                                          for bs = 1:length(M.S)))
    end
    return 0.
end

function generate_successor(â„³::SOMDP,
                         state::MemoryState,
                        action::MemoryAction)
    thresh = rand()
    p = 0.
    T = â„³.T(â„³, state, action)
    for (sâ€², stateâ€²) âˆˆ enumerate(â„³.S)
        p += T[sâ€²]
        if p >= thresh
            return stateâ€²
        end
    end
end

function simulate(â„³::SOMDP,
                   ğ’±::ValueIterationSolver)
    M, S, A, R, state = â„³.M, â„³.S, â„³.A, â„³.R, â„³.sâ‚€
    true_state, G = M.sâ‚€, M.G
    rewards = Vector{Float64}()
    for i = 1:100
        episode_reward = 0.0
        while true_state âˆ‰ G
            if length(state.action_list) > 0
                cum_cost += 3
                state = MemoryState(true_state, Vector{CampusAction}())
            else
                s = index(state, S)
                true_s = index(true_state, M.S)
                a = ğ’±.Ï€[true_s]
                action = M.A[a]
                memory_action = MemoryAction(action.value)
                cum_cost += M.C[true_s][a]
                state = generate_successor(â„³, state, memory_action)
                if length(state.action_list) == 0
                    true_state = state.state
                else
                    true_state = generate_successor(M, true_s, a)
                end
            end
        end
    end
    println("Average cost to goal: $cum_cost")
end

function simulate(â„³::SOMDP, â„’::LAOStarSolver, ğ’±::ValueIterationSolver)
    M, S, A, R = â„³.M, â„³.S, â„³.A, â„³.R
    r = Vector{Float64}()
    # println("Expected cost to goal: $(â„’.V[index(state, S)])")
    for i=1:1
        state, true_state = â„³.sâ‚€, M.sâ‚€
        episode_reward = 0.0
        while true
            s = index(state, S)
            a, _ = solve(â„’, ğ’±, â„³, s)
            action = A[a]
            println("Taking action $action in memory state $state
                                           in true state $true_state.")
            if action.value == "QUERY"
                state = MemoryState(true_state, Vector{DomainAction}())
                episode_reward -= 3
            else
                true_s = index(true_state, M.S)
                episode_reward += M.R[true_s][a]
                state = generate_successor(â„³, state, A[a])
                if length(state.action_list) == 0
                    true_state = state.state
                else
                    true_state = generate_successor(M, true_s, a)
                end
            end

            if terminal(state) || terminal(true_state)
                println("Terminating in state $state and
                                   true state $true_state.")
                break
            end
        end
        push!(r, episode_reward)
        # println("Episode $i || Total cumulative reward:
        #              $(mean(episode_reward)) â¨¦ $(std(episode_reward))")
    end
    # println("Reached the goal.")
    println("Total cumulative reward: $(mean(r)) â¨¦ $(std(r))")
end
#
# function simulate(â„³::MemorySSP, ğ’±::ValueIterationSolver, Ï€::MCTSSolver)
#     M, S, A, C = â„³.M, â„³.S, â„³.A, â„³.C
#     costs = Vector{Float64}()
#     # println("Expected cost to goal: $(â„’.V[index(state, S)])")
#     for i=1:1
#         state, true_state, G = â„³.sâ‚€, M.sâ‚€, M.G
#         episode_cost = 0.0
#         while true_state âˆ‰ G
#             # s = index(state, S)
#             # a, _ = solve(â„’, ğ’±, â„³, s)
#             action = solve(Ï€, state)
#             # action = A[a]
#             println("Taking action $action in memory state $state in true state $true_state.")
#             if action.value == "query"
#                 state = MemoryState(true_state, Vector{CampusAction}())
#                 episode_cost += 3
#             else
#                 true_s = index(true_state, M.S)
#                 a = index(action, A)
#                 episode_cost += M.C[true_s][a]
#                 state = generate_successor(â„³, state, action)
#                 if length(state.action_list) == 0
#                     true_state = state.state
#                 else
#                     true_state = generate_successor(M, true_s, a)
#                 end
#             end
#         end
#         push!(costs, episode_cost)
#         println("Episode $i           Total cumulative cost: $(mean(costs)) â¨¦ $(std(costs))")
#     end
#     # println("Reached the goal.")
#     println("Total cumulative cost: $(mean(costs)) â¨¦ $(std(costs))")
# end

function build_model(M::MDP)
    Î´ = 2
    S, sâ‚€ = generate_states(M, Î´)
    A = generate_actions(M)
    Ï„ = Dict{Int, Dict{Int, Dict{Int, Float64}}}()
    â„³ = SOMDP(M, S, A, generate_transitions, generate_reward, sâ‚€,
                   Ï„, Î´, generate_heuristic)
    return â„³
end

function solve_model(â„³, ğ’±)
    â„’ = LAOStarSolver(100000, 1000., 1.0, .001, Dict{Integer, Integer}(),
         zeros(length(â„³.S)), zeros(length(â„³.S)),
         zeros(length(â„³.S)), zeros(length(â„³.A)))
    # ğ’° = UCTSolver(zeros(length(â„³.S)), Set(), 1000, 100, 0)
    # U(state) = minimum(heuristic(â„³, ğ’±.V, state, action) for action in â„³.A)
    # U(state, action) = heuristic(â„³, ğ’±.V, state, action)

    # Ï€ = MCTSSolver(â„³, Dict(), Dict(), U, 10, 10000, 100.0)
    S, s = â„³.S, â„³.sâ‚€
    a, total_expanded = @time solve(â„’, ğ’±, â„³, index(s, S))
    # a = @time solve(ğ’°, ğ’±, â„³, )
    # a = @time solve(Ï€, s)
    # return Ï€, a
    println("LAO* expanded $total_expanded nodes.")
    println("Expected cost to goal: $(â„’.V[index(s,S)])")
    return â„’, â„’.V[index(s, S)]
    # return ğ’°, ğ’°.V[index(s, S)]
end

function main()
    domain_map_file = joinpath(@__DIR__, "..", "maps", "collapse_1.txt")

    println("Starting...")
    M = build_model(domain_map_file)
    ğ’± = solve_model(M)

    â„³ = @time build_model(M)
    print(â„³.S[length(â„³.S)])
    # sâ€² = MemoryState(DomainState(5, 2, 'â†', 0, Integer[0,0,0]), DomainAction[])
    # a = MemoryAction('â†‘')
    # #
    # for (s, state) in enumerate(â„³.S)
    #     t = â„³.T(â„³, state, a)[index(sâ€², â„³.S)]
    #     if t != 0.0
    #         println("Transition probability $t of previous state $state")
    #     end
    # end

    # simulate(â„³, ğ’±)
    println("Solving...")
    println(length(â„³.S))
    â„’, expected_cost = solve_model(â„³, ğ’±)
    # # ğ’°, expected_cost = solve_model(â„³, ğ’±)
    # # Ï€, a = solve_model(â„³, ğ’±)
    # # expected_cost = Ï€.Q[(â„³.sâ‚€, a)]
    println("Expected reward from initial state: $expected_cost")
    println("Simulating...")
    simulate(â„³, â„’, ğ’±)


    # simulate(â„³, ğ’±, Ï€)
end

main()

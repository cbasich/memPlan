using Combinatorics
using Statistics
using Random

import Base.==

include("MDP.jl")
include(joinpath(@__DIR__, "..", "..", "..", "solvers", "VIMDPSolver.jl"))
include(joinpath(@__DIR__, "..", "..", "..", "solvers", "LAOStarSolver.jl"))
include(joinpath(@__DIR__, "..", "..", "..", "solvers", "UCTSolverMDP.jl"))
include(joinpath(@__DIR__, "..", "..", "..", "solvers", "MCTSSolver.jl"))
include(joinpath(@__DIR__, "..", "..", "..", "solvers", "FLARESSolver.jl"))


function index(element, collection)
    for i=1:length(collection)
        if collection[i] == element
            return i
        end
    end
    return -1
end

struct MemoryState
    state::DomainState
    action_list::Vector{DomainAction}
end

function ==(a::MemoryState, b::MemoryState)
    return (a.state == b.state && a.action_list == b.action_list)
end

function Base.hash(a::MemoryState, h::UInt)
    h = hash(a.state, h)
    for act âˆˆ a.action_list
        h = hash(act, h)
    end
    return h
end

struct MemoryAction
    value::Union{String,Char}
end

function Base.hash(a::MemoryAction, h::UInt)
    return hash(a.value, h)
end

function ==(a::MemoryAction, b::DomainAction)
    return isequal(a.value, b.value)
end


struct SOMDP
    M::MDP
    S::Vector{MemoryState}
    A::Vector{MemoryAction}
    T::Dict{Int, Dict{Int, Vector{Tuple{Int, Float64}}}}
    R::Function
   sâ‚€::MemoryState
    Î´::Integer
    H::Function
    Sindex::Dict{MemoryState, Integer}
    Aindex::Dict{MemoryAction, Integer}
end

function SOMDP(M::MDP,
               S::Vector{MemoryState},
               A::Vector{MemoryAction},
               T::Dict{Int, Dict{Int, Vector{Tuple{Int, Float64}}}},
               R::Function,
               sâ‚€::MemoryState,
               Î´::Integer,
               H::Function)

    Aindex, Sindex = generate_index_dicts(A, S)
    â„³ = SOMDP(M, S, A, T, generate_reward, sâ‚€, Î´, generate_heuristic, Sindex, Aindex)
end

function generate_index_dicts(A::Vector{MemoryAction}, S::Vector{MemoryState})
    Aindex = Dict{MemoryAction, Integer}()
    for (i, a) âˆˆ enumerate(A)
        Aindex[a] = i
    end
    Sindex = Dict{MemoryState, Integer}()
    for (i, a) âˆˆ enumerate(S)
        Sindex[a] = i
    end
    return Aindex, Sindex
end

function generate_states(M::MDP, Î´::Integer)
    A = M.A

    S = Vector{MemoryState}()
    sâ‚€ = -1
    for depth in 0:Î´
        for (i, state) in enumerate(M.S)
            if depth == 0
                s = MemoryState(state, Vector{DomainAction}())
                push!(S, s)
                if state == M.sâ‚€
                    sâ‚€ = length(S)
                end
            else
                for action_list âˆˆ collect(Base.product(ntuple(i->A, depth)...))
                    s = MemoryState(state, [a for a âˆˆ action_list])
                    push!(S, s)
                end
            end
        end
    end
    push!(S, MemoryState(DomainState(-1, -1, 'â†‘', -1, Integer[-1,-1,-1]),
                         DomainAction[DomainAction("aid")]))
    return S, S[sâ‚€]
end

function terminal(state::MemoryState)
    return terminal(state.state)
end

function generate_actions(M::MDP)
    A = [MemoryAction(a.value) for a in M.A]
    push!(A, MemoryAction("QUERY"))
    return A
end

function eta(state::MemoryState)
    return 1 - (0.3 * state.state.ğ“)
end

function eta(state::DomainState)
    return 1 - (0.3 * state.ğ“)
end

function eta(action::MemoryAction,
             stateâ€²::MemoryState)
    return 1 - (0.3 * stateâ€².state.ğ“)
end

function generate_transitions(â„³::SOMDP)
    M, S, A, T = â„³.M, â„³.S, â„³.A, â„³.T
    for (s, state) in enumerate(S)
        T[s] = Dict{Int, Vector{Pair{Int, Float64}}}()
        for (a, action) in Iterators.reverse(enumerate(A))
            T[s][a] = generate_transitions(â„³, s, a)
        end
    end
end

function check_transition_validity(â„³::SOMDP)
    M, S, A, T = â„³.M, â„³.S, â„³.A, â„³.T
    for (s, state) in enumerate(S)
        for (a, action) in enumerate(A)
            mass = 0.0
            for (sâ€², p) in T[s][a]
                mass += p
            end
            if round(mass; digits=5) != 1.0
                println("Transition error at state $state and action $action.")
                println("State index: $s      Action index: $a")
                println("Total probability mass of $mass.")
                println("Transition vector is the following: \n $(T[s][a])")
                @assert false
            end
        end
    end
end

function generate_transitions(â„³::SOMDP, s::Int, a::Int)
    M, S, A = â„³.M, â„³.S, â„³.A
    state, action = S[s], A[a]
    if state.state.x == -1
        return [(s, 1.0)]
    end

    T = Vector{Tuple{Int, Float64}}()
    # Inside a domain state
    if isempty(state.action_list)
        if action.value == "QUERY" # Do nothing
            return [(s, 1.0)]
        else
            i = argmax(M.T[s][a])
            if M.T[i] == 1.0
                return [(i, 1.0)]
            else
                mass = 0.0
                for (sâ€², stateâ€²) in enumerate(M.S)
                    p = M.T[s][a][sâ€²]
                    if p == 0.0
                        continue
                    end
                    p *= eta(stateâ€²)
                    mass += p
                    push!(T, (sâ€², round(p; digits=5)))
                end
                msâ€² = length(M.S) + length(M.A) * (s-1) + a
                push!(T, (msâ€², 1.0 - round(mass; digits=5)))
            end
        end
    elseif action.value == "QUERY"  # Here and below is in memory state
        prev_action = MemoryAction(last(state.action_list).value)
        p_a = â„³.Aindex[prev_action]
        prev_state = MemoryState(state.state,
                      state.action_list[1:length(state.action_list) - 1])
        p_s = â„³.Sindex[prev_state]

        len = length(â„³.M.S)
        tmp = Dict{Int, Float64}()
        for (bs, b) in â„³.T[p_s][a]
            for (bsâ€², bâ€²) in â„³.T[bs][p_a]
                if bsâ€² > len
                    continue
                end
                if !haskey(tmp, bsâ€²)
                    tmp[bsâ€²] = 0.0
                end
                tmp[bsâ€²] += b * â„³.M.T[bs][p_a][bsâ€²]
            end
        end
        for k in keys(tmp)
            push!(T, (k, round(tmp[k]; digits=5)))
        end
        # for sâ€² = 1:length(M.S)
        #     mass = 0.0
        #     for (bs, b) in â„³.T[p_s][a]
        #         for (bsâ€², bâ€²) in â„³.T[bs][p_a]
        #             if bsâ€² == sâ€²
        #                 mass += b * â„³.M.T[bs][p_a][bsâ€²]
        #             end
        #         end
        #     end
        #     if mass != 0.0
        #         push!(T, (sâ€², round(mass; digits=5)))
        #     end
        # end
    elseif length(state.action_list) == â„³.Î´
        return [(length(â„³.S), 1.0)]
    else # Taking non-query action in memory state before depth Î´ is reached
        action_listâ€² = [action for action in state.action_list]
        push!(action_listâ€², DomainAction(action.value))
        mstateâ€² = MemoryState(state.state, action_listâ€²)
        msâ€² = â„³.Sindex[mstateâ€²]

        tmp = Dict{Int, Float64}()
        len = length(â„³.M.S)
        mass = 0.0
        for (bs, b) in â„³.T[s][length(A)]
            for (bsâ€², bâ€²) in â„³.T[bs][a]
                if bsâ€² > len
                    continue
                end
                if !haskey(tmp, bsâ€²)
                    tmp[bsâ€²] = 0.0
                end
                tmp[bsâ€²] += b * M.T[bs][a][bsâ€²] * eta(S[bsâ€²])
            end
        end
        for k in keys(tmp)
            mass += tmp[k]
            push!(T, (k, round(tmp[k]; digits=5)))
        end

        #     for sâ€² = 1:length(M.S)
        #         p = M.T[bs][a][sâ€²]
        #         if p == 0.0
        #             continue
        #         end
        #         pâ€² = b * p * eta(S[sâ€²])
        #         mass += pâ€²
        #         push!(T, (sâ€², round(pâ€²; digits=5)))
        #     end
        # end
        push!(T, (msâ€², round(1.0-mass; digits=5)))
    end
    return T
end

# function generate_transitions(â„³::SOMDP,
#                            state::MemoryState,
#                           action::MemoryAction)
#     M, S, A = â„³.M, â„³.S, â„³.A
#     T = zeros(length(S))
#     if state.state.x == -1
#         T[length(â„³.S)] = 1.0
#         return T
#     end
#     if isempty(state.action_list)
#         s, a = index(state, S), index(action, A)
#         if action.value == "QUERY"
#             T[s] = 1.
#             return T
#         elseif maximum(M.T[s][a]) == 1.
#             T[argmax(M.T[s][a])] = 1.
#             return T
#         else
#             msâ€² = length(M.S) + length(M.A) * (s-1) + a
#             T[msâ€²] = eta(action, â„³.S[msâ€²])
#             for (sâ€², stateâ€²) in enumerate(M.S)
#                 T[sâ€²] = M.T[s][a][sâ€²] * (1 - T[msâ€²])
#             end
#         end
#     elseif action.value == "QUERY"
#         actionâ‚š = MemoryAction(last(state.action_list).value)
#         stateâ‚š = MemoryState(state.state,
#                              state.action_list[1:length(state.action_list)-1])
#         sâ‚š = index(stateâ‚š, â„³.S)
#         aâ‚š = index(actionâ‚š, â„³.A)
#         for sâ€² = 1:length(M.S)
#             T[sâ€²] = recurse_transition(â„³, sâ‚š, aâ‚š, sâ€²)
#         end
#     elseif length(state.action_list) == â„³.Î´
#         T[length(â„³.S)] = 1.
#     else
#         s, a = index(state, S), index(action, A)
#         action_listâ€² = copy(state.action_list)
#         push!(action_listâ€², DomainAction(action.value))
#         mstateâ€² = MemoryState(state.state, action_listâ€²)
#         ## TODO: Below, we assume a fixed value of gaining observability from a
#         ##       memory state. This part should be changed to be based on eta
#         ##       of belief state of the memory state.
#         T[index(mstateâ€², S)] = .75
#         for sâ€² = 1:length(M.S)
#             T[sâ€²] = 0.25recurse_transition(â„³, s, a, sâ€²)
#         end
#     end
#     return T
# end

function generate_reward(â„³::SOMDP, s::Int, a::Int)
    M, S, A = â„³.M, â„³.S, â„³.A
    state, action = S[s], A[a]
    if state.state.x == -1
        return -10
    elseif action.value == "QUERY"
        return (-2 * sum(state.state.ğ’«))
    elseif length(state.action_list) == 0
        return M.R[s][a]
    else
        r = 0.0
        for (bs, b) in â„³.T[s][length(A)]
            r += b * â„³.M.R[bs][a]
        end
        return r
    end
end

function generate_heuristic(â„³::SOMDP, V::Vector{Float64}, s::Int, a::Int)
    M, S, A = â„³.M, â„³.S, â„³.A
    state, action = S[s], A[a]
    if state.state.x == -1
        return 0.
    end
    if length(state.action_list) == 0
        return V[s]
    else
        h = 0.0
        for (bs, b) in â„³.T[s][length(A)]
            h += b * V[bs]
        end
        return h
    end
    return 0.
end

function generate_successor(â„³::SOMDP,
                         state::MemoryState,
                        action::MemoryAction)::MemoryState
    thresh = rand()
    p = 0.
    T = â„³.T[â„³.Sindex[state]][â„³.Aindex[action]]
    for (sâ€², prob) âˆˆ T
        p += prob
        if p >= thresh
            return â„³.S[sâ€²]
        end
    end
end


function generate_successor(â„³::SOMDP,
                             s::Integer,
                             a::Integer)::Integer
    thresh = rand()
    p = 0.
    T = â„³.T[s][a]
    for (sâ€², prob) âˆˆ T
        p += prob
        if p >= thresh
            return sâ€²
        end
    end
end

function simulate(â„³::SOMDP,
                   ğ’±::ValueIterationSolver)
    M, S, A, R, state = â„³.M, â„³.S, â„³.A, â„³.R, â„³.sâ‚€
    true_state, G = M.sâ‚€, M.G
    rewards = Vector{Float64}()
    for i = 1:10
        episode_reward = 0.0
        while true_state âˆ‰ G
            if length(state.action_list) > 0
                cum_cost += 3
                state = MemoryState(true_state, Vector{CampusAction}())
            else
                s = â„³.Sindex[state]
                true_s = â„³.Sindex[true_state]index(true_state, M.S)
                a = ğ’±.Ï€[true_s]
                action = M.A[a]
                memory_action = MemoryAction(action.value)
                cum_cost += M.C[true_s][a]
                state = generate_successor(â„³, state, memory_action)
                if length(state.action_list) == 0
                    true_state = state.state
                else
                    true_state = generate_successor(M, true_s, a)
                end
            end
        end
    end
    println("Average cost to goal: $cum_cost")
end

function simulate(â„³::SOMDP,
                   ğ’±::ValueIterationSolver,
                   ğ’®::Union{LAOStarSolver,FLARESSolver},
                   m::Int,
                   v::Bool)
    M, S, A, R = â„³.M, â„³.S, â„³.A, â„³.R
    r = Vector{Float64}()
    # println("Expected cost to goal: $(â„’.V[index(state, S)])")
    for i âˆˆ 1:m
        state, true_state = â„³.sâ‚€, M.sâ‚€
        episode_reward = 0.0
        while true
            s = index(state, S)
            a = ğ’®.Ï€[s]
            action = A[a]
            if v
                println("Taking action $action in memory state $state
                                               in true state $true_state.")
            end
            if action.value == "QUERY"
                state = MemoryState(true_state, Vector{DomainAction}())
                episode_reward -= 3
            else
                true_s = index(true_state, M.S)
                episode_reward += M.R[true_s][a]
                state = generate_successor(â„³, state, A[a])
                if length(state.action_list) == 0
                    true_state = state.state
                else
                    true_state = generate_successor(M, true_s, a)
                end
            end

            if terminal(state) || terminal(true_state)
                if v
                    println("Terminating in state $state and
                                       true state $true_state.")
                end
                break
            end
        end
        push!(r, episode_reward)
        # println("Episode $i || Total cumulative reward:
        #              $(mean(episode_reward)) â¨¦ $(std(episode_reward))")
    end
    # println("Reached the goal.")
    println("Total cumulative reward: $(mean(r)) â¨¦ $(std(r))")
end
#
function simulate(â„³::SOMDP,
                   ğ’±::ValueIterationSolver,
                   Ï€::MCTSSolver)
    M, S, A, R = â„³.M, â„³.S, â„³.A, â„³.R
    rewards = Vector{Float64}()
    # println("Expected cost to goal: $(â„’.V[index(state, S)])")
    for i=1:1
        state, true_state = â„³.sâ‚€, M.sâ‚€
        r = 0.0
        while true
            # s = index(state, S)
            # a, _ = solve(â„’, ğ’±, â„³, s)
            action = @time solve(Ï€, state)
            # action = A[a]
            println("Taking action $action in memory state $state
                                           in true state $true_state.")
            if action.value == "QUERY"
                state = MemoryState(true_state, Vector{DomainAction}())
                r -= 3
            else
                true_s = index(true_state, M.S)
                a = index(action, A)
                r += M.R[true_s][a]
                state = generate_successor(â„³, state, action)
                if length(state.action_list) == 0
                    true_state = state.state
                else
                    true_state = generate_successor(M, true_s, a)
                end
            end
            if terminal(state) || terminal(true_state)
                println("Terminating in state $state and
                                   true state $true_state.")
                break
            end
        end
        push!(rewards, r)
        # println("Episode $i  Total cumulative cost: $(mean(costs)) â¨¦ $(std(costs))")
    end
    # println("Reached the goal.")
    println("Average reward: $(mean(costs)) â¨¦ $(std(costs))")
end

function build_model(M::MDP,
                     Î´::Int)
    S, sâ‚€ = generate_states(M, Î´)
    A = generate_actions(M)
    T = Dict{Int, Dict{Int, Vector{Tuple{Int, Float64}}}}()
    â„³ = SOMDP(M, S, A, T, generate_reward, sâ‚€, Î´, generate_heuristic)
    generate_transitions(â„³)
    println("Checking transition validity")
    check_transition_validity(â„³)
    return â„³
end

function solve_model(â„³, ğ’±, solver)
    S, s = â„³.S, â„³.sâ‚€
    println("Solving...")

    if solver == "laostar"
        â„’ = LAOStarSolver(100000, 1000., 1.0, .001, Dict{Integer, Integer}(),
            zeros(length(â„³.S)), zeros(length(â„³.S)),
            zeros(length(â„³.S)), zeros(length(â„³.A)))
        a, total_expanded = @time solve(â„’, ğ’±, â„³, index(s, S))
        println("LAO* expanded $total_expanded nodes.")
        println("Expected reward: $(â„’.V[index(s,S)])")
        return â„’
    elseif solver == "uct"
        ğ’° = UCTSolver(zeros(length(â„³.S)), Set(), 1000, 100, 0)
        a = @time solve(ğ’°, ğ’±, â„³)
        println("Expected reward: $(ğ’°.V[index(s, S)])")
        return ğ’°
    elseif solver == "mcts"
        U(state) = maximum(generate_heuristic(â„³, ğ’±.V, state, action)
                                                  for action in â„³.A)
        U(state, action) = generate_heuristic(â„³, ğ’±.V, state, action)
        Ï€ = MCTSSolver(â„³, Dict(), Dict(), U, 20, 100, 100.0)
        a = @time solve(Ï€, s)
        println("Expected reard: $(Ï€.Q[(s, a)])")
        return Ï€, a
    elseif solver == "flares"
        â„± = FLARESSolver(100000, 2, false, false, -1000, 0.001,
                         Dict{Integer, Integer}(),
                         zeros(length(â„³.S)),
                         zeros(length(â„³.S)),
                         Set{Integer}(),
                         Set{Integer}(),
                         zeros(length(â„³.A)))
        a, num = @time solve(â„±, ğ’±, â„³, index(s, S))
        println("Expected reward: $(â„±.V[index(s, S)])")
        return â„±
    end
end

function solve(â„³, ğ’±, solver::String)
    if solver == "laostar"
        return solve_model(â„³, ğ’±, solver)
    elseif solver == "uct"
        return solve_model(â„³, ğ’±, solver)
    elseif solver == "mcts"
        return solve_model(â„³, ğ’±, solver)
    elseif solver == "flares"
        return solve_model(â„³, ğ’±, solver)
    else
        println("Error.")
    end
end

# This is for Connor's benefit running in IDE

function run_somdp()
    ## PARAMS
    MAP_PATH = joinpath(@__DIR__, "..", "maps", "collapse_2.txt")
    SOLVER = "laostar"
    SIM = false
    SIM_COUNT = 1
    VERBOSE = false
    DEPTH = 2


    ## MAIN SCRIPT
    println("Building MDP...")
    M = build_model(MAP_PATH)
    println("Solving MDP...")
    ğ’± = solve_model(M)
    println("Building SOMDP...")
    â„³ = @time build_model(M, DEPTH)
    println("Solving SOMDP...")
    solver = @time solve(â„³, ğ’±, SOLVER)

    if SIM
        println("Simulating...")
        simulate(â„³, ğ’±, solver, SIM_COUNT, VERBOSE)
    end
end

#run_somdp()
